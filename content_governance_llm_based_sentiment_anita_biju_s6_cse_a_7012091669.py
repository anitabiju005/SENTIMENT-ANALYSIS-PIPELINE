# -*- coding: utf-8 -*-
"""Content Governance - LLM based Sentiment_ANITA_BIJU_S6_CSE-A_7012091669.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nim3H3ClAUGVddFzVaChbQtEgG3nfCkD
"""

#Install libraries
!pip install --quiet transformers datasets keybert spacy contractions
!python -m spacy download en_core_web_sm --quiet

#Import models and libraries
import re
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline
from datasets import load_dataset, Dataset
import spacy
import contractions
from keybert import KeyBERT
from sklearn.model_selection import train_test_split

#Load Dataset
dataset = load_dataset("tweet_eval", "sentiment")
subset_size = 500
reviews = dataset["train"][:subset_size]["text"]
true_labels = dataset["train"][:subset_size]["label"]

# Map numeric labels to sentiment
label_map = {0:"NEGATIVE", 1:"NEUTRAL", 2:"POSITIVE"}
true_labels_mapped = [label_map[l] for l in true_labels]

# Train/Validation split
reviews_train, reviews_val, labels_train, labels_val = train_test_split(
    reviews, true_labels, test_size=0.2, random_state=42
)

print("Train samples:", len(reviews_train))
print("Validation samples:", len(reviews_val))

#Preprocessing Function
nlp = spacy.load("en_core_web_sm")
priority_words = ["don't", "no", "not", "never"]

def preprocess_text(text):
    # Expand contractions
    text = contractions.fix(text)
    text = text.lower()
    # Keep apostrophes, remove other special chars
    text = re.sub(r"[^a-zA-Z0-9\s']", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

#Remove proper nouns
def remove_proper_nouns(text):
    doc = nlp(text)
    return " ".join([token.text for token in doc if token.pos_ != "PROPN"])

#Divide text into chunks
def chunk_text(text, chunk_size=150):
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

#Tokenization and Dataset Formatting
model_name = "cardiffnlp/twitter-roberta-base-sentiment-latest"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Create HuggingFace Datasets
train_dataset = Dataset.from_dict({"text": reviews_train, "labels": labels_train})
val_dataset   = Dataset.from_dict({"text": reviews_val,   "labels": labels_val})

# Tokenize
def tokenize_batch(batch):
    return tokenizer(batch['text'], padding=True, truncation=True, max_length=256)

train_dataset = train_dataset.map(tokenize_batch, batched=True)
val_dataset   = val_dataset.map(tokenize_batch, batched=True)

# Set torch format
train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])

#Fine Tuning
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

training_args = TrainingArguments(
    output_dir="./finetuned_model",
    num_train_epochs=2,
    per_device_train_batch_size=8,
    learning_rate=2e-5,
    logging_dir="./logs",
    logging_steps=10,
    save_steps=50
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# Train the model
trainer.train()

#Create pipeline
sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model=model,
    tokenizer=tokenizer,
    truncation=True,
    max_length=512
)

#Structured Sentiment Summary
def structured_sentiment_summary(texts, top_n=3, chunk_size=150):
    if isinstance(texts, str):
        texts = [texts]

    kw_model = KeyBERT()
    results = []

    for t in texts:
        #Sentiment
        out = sentiment_pipeline(t)[0]
        label = out["label"].upper()        # POSITIVE / NEGATIVE / NEUTRAL
        conf  = round(out["score"], 3)

        #Preprocess + remove proper nouns
        clean_text = preprocess_text(t)
        clean_text = remove_proper_nouns(clean_text)

        #Chunk text for KeyBERT
        chunks = chunk_text(clean_text, chunk_size)

        #Extract key supporting phrases
        keywords = []
        for chunk in chunks:
            kws = kw_model.extract_keywords(
                chunk,
                keyphrase_ngram_range=(1,3),
                stop_words='english',
                top_n=5
            )
            for kw in kws:
                phrase = kw if isinstance(kw, str) else kw[0]
                keywords.append(phrase)

        # 4a️⃣ Add priority words if present
        for pw in priority_words:
            if pw in clean_text.split() and pw not in keywords:
                keywords.insert(0, pw)

        # 4b️⃣ Build unique list and ensure EXACT top_n phrases
        unique_keywords = []
        for kw in keywords:
            if kw not in unique_keywords:
                unique_keywords.append(kw)

        # Fallback: if fewer than top_n, fill from cleaned text
        if len(unique_keywords) < top_n:
            extra_words = clean_text.split()
            for w in extra_words:
                if w not in unique_keywords:
                    unique_keywords.append(w)
                if len(unique_keywords) >= top_n:
                    break

        # FINAL: exactly top_n supporting phrases
        top_phrases = unique_keywords[:top_n]

        #Follow-up suggestion
        follow_up = ""
        if label == "NEGATIVE":
            follow_up = "Consider rephrasing your review or providing constructive feedback."

        results.append({
            "text": t,
            "predicted_sentiment": label,
            "confidence": conf,
            "top_supporting_phrases": top_phrases,
            "follow_up_suggestions": follow_up
        })

    return pd.DataFrame(results)

#Test Summary Report
df_summary = structured_sentiment_summary(reviews_val)
df_summary

#Evaluating pipeline
pred_df = structured_sentiment_summary(reviews)
pred_labels = pred_df['predicted_sentiment'].tolist()  # string labels

# Compute metrics
from sklearn.metrics import accuracy_score, f1_score
accuracy = accuracy_score(true_labels_mapped, pred_labels)
f1 = f1_score(true_labels_mapped, pred_labels, average='weighted')

print(f"Accuracy: {accuracy:.3f}")
print(f"Weighted F1-score: {f1:.3f}")

#Generating numeric predictions for validation set
device = next(model.parameters()).device

preds = []

for batch in val_dataset:
    inputs = {
        "input_ids": batch["input_ids"].unsqueeze(0).to(device),
        "attention_mask": batch["attention_mask"].unsqueeze(0).to(device)
    }

    with torch.no_grad():
        output = model(**inputs)
        logits = output.logits
        pred = torch.argmax(logits, dim=1).item()
        preds.append(pred)

misclassified = []

for i in range(len(labels_val)):
    if preds[i] != labels_val[i]:
        misclassified.append((reviews_val[i][:300], labels_val[i], preds[i]))

print("\n--- Error Analysis (Sample 10 misclassifications) ---")
for text, true, pred in misclassified[:10]:
    print("\nTEXT:", text.replace("\n", " "))
    print("TRUE LABEL:", true, "| PRED:", pred)

print("\nTOTAL MISCLASSIFICATIONS =", len(misclassified), "samples")